# **Continuemos con la terminal (Shell)**

En esta clase conocerémos cuatro comandos grandes comandos ```grep```, ```awk```, ```sed```, ```wget-curl``` y lo combinarémos con lo aprendido la clase pasada.

## Ejercicio 1  

Muchas veces tenemos que utilizar datos que están disponibles en linea y en ocasiones son muy pesados o necesitamos bajar muchos al mismo tiempo, para eso existen los comandos ```wget``` y ```curl```  que nos permiten bajar archivos desde internet de manera fácil y súper rápida. Bajemos un archivo del libro *Bioinformatics data skills* ```wget -O file.txt 'https://raw.githubusercontent.com/vsbuffalo/bds-files/master/chapter-07-unix-data-tools/Mus_musculus.GRCm38.75_chr1.bed'```

Ahora con ```curl``` *see URL*

```curl "https://api.openstreetmap.org/api/0.6/map?bbox=11.54,48.14,11.543,48.145"```

¿Qué pasó?, guárdenlo en un archivo, lo dos comandos funcionan muy bien

## Ejercicio 2

Ahora vamos a aprender a obtener determinada información de los archivos, por favor descarguen el archivo *.bed del libro *Bioinformatics data skills* y calculemos el número de lineas que tiene usando el comando ```wc```, de la siguiente forma ```wc Mus_musculus.GRCm38.75_chr1.bed``` ¿Qué obtuvieron?, lo que arroja ```wc``` son el número de palabras, lineas y caracteres. ¿Cúal creen que sea el más importante?. Yo el que más uso son las lineas, entren al manual de ```wc``` y cuéntenme si existe un argumento para solo obtener las lineas

Ahora diganme cuánto pesa el archi *.bed y observemos como luce, ¿Cómo lo harían?

También podemos saber cuántas columnas tiene un archivo, para eso podemos usar ```awk```, una herramienta súper chévere que trabaja muy bien con archivos delimitados por ```\t``` o ```,```. Calculemos el número de columnas de nuestra archivo de trabajo.

```awk -F "\t" '{print NF; exit}' Mus_musculus.GRCm38.75_chr1.bed``` ya les mostraré cómo funcionan

Ahora descarguen el siguiente archivo de [GBIF](https://raw.githubusercontent.com/fcsalgado/bioinformatics_urosario/master/files/gbif_ocurrences.csv) usando curl o wget diganme cuantas columnas y filas tiene

Muchas veces los archivos tienen una serie de comentarios informativos que impiden el cálculo de por ejemplo el número de columnas y filas, quiero que descarguen el siguiente [VCF file](https://raw.githubusercontent.com/fcsalgado/bioinformatics_urosario/master/files/random_ploythore.vcf), pronto entenderemos este formato. Por ahora lo que quiero es que teniendo que las primeras 10 lineas son de comentarios calculen el número de columnas y filas. ¿Cómo lo harían?


## Ejercicio 3

Vamos a ver una herramienta fantástisca para seleccionar columnas, les presento al comando  ```cut```, que nos permite seleccionar las columnas y carácteres de que deseemos. para ello debemos usar el argumento ```cut -f <columnas> <nombre del archivo>```. Quiero que seleccionen el nombre de la especie junto con la latitud y longitud. ¿Cómo lo haría?. Ahora hagan lo mismo, pero seleccionen solo la primera fila del output. ¿Es esto posible?

## Ejercicio 4

Este es una de mis comandos favoritos ```grep```. Su función es capturar patrones específicos en un texto. Es un comando muy poderoso. Para ver como funcionan bajemos la siguiente [lista de secuencias](https://raw.githubusercontent.com/fcsalgado/bioinformatics_urosario/master/files/gasteracantha.fasta)

Imaginen que tienen que capturar solo los nombres de las secuencias. utilizando la siguiete lógicas ```grep <patrón> <nombre del archivo>```, ¿Qué harían?

Una opción interesante es que podemos capturar todo lo contrario al patrón que deseamos usando el argumento ```-v```, ¿Qué obtuvieron?

Imaginen ahora que tienen una lista de archivos como la [siguiente](https://github.com/fcsalgado/bioinformatics_urosario/blob/master/files/lista_fastas.zip)

Usando ```grep``` encuentren que archivos tienen el siguiente patrón de secuencia ```ATTGGAA```. ¿Cómo lo harían?

## Ejercicio 5

```grep``` tiene más argumentos que debemos explorar. Piensen ahora que quieren obtener una secuencia fasta en específico, por ejemplo aquella de la secuencia ```SEQ105```, podemos usar el argumento ```-A<lineas>``` que simboliza *after*, obviamente también existe el argumento ```-B<lineas>``` que simboliza *before*. Sabiendo que cada encabezado fasta va seguido de 9 lineas se secuencia, *grepeen* encabezado y la secuencia completa de la secuencia ```SEQ105```

Con ```grep``` también podemos usar expresiones regulares simples. Por ejemplo imaginen que queremos todos las secuencias con códigos mayores a 100, ¿Cómo los hacemos? Denme sus ideas

Para activar la expresiones regulares deben usar el argumento ```-E```. Imaginemos que queremos dos secuencias específicas ```SEQ20|SEQ90``` el ```|``` en este caso representa o. ```grep -A9 -E  "SEQ20|SEQ90" gasteracantha.fasta```

Imaginemos que queremos contar ahora cuántas secuencias tenemos, el argumento ```-c``` nos lo permite, ¿Cómo lo hacemos? ¿Esta será la única solución?

¡Ahora usemos las expresiones regulares!

Necesito que del archivo [GBIF](https://raw.githubusercontent.com/fcsalgado/bioinformatics_urosario/master/files/gbif_ocurrences.csv) las coordenadas (Latitud y Longitud) usando expresiones regulares

¿Habrá una opción para solo dejar el match? ¡por supuesto! es ```-o```

## Ejercicio 6

El siguiente comando es un lenguaje en sí, y puede llegar a tener terminos y referencias complejas. Hoy aprenderemos lo básico. El comando se llama  ```awk``` y si están en mac es mejor usar ```gawk```

En ```awk``` cada record es una línea y cada espacio separado por tab es una columna y su accionar es ```patrón {acción}``` cada patrón es una expresión o una expresión regular

¿Qué sucede si ejecutamos el siguiente comando?

```awk '{ print $0 }' gbif_ocurrences.csv```

Ahora podemos hacer la misma función de ```cut``` usando ```awk``` usando el archivo .bed del libro *Bioinformatic ata skills* que pueden descargar de [aquí](https://raw.githubusercontent.com/vsbuffalo/bds-files/master/chapter-07-unix-data-tools/example.bed)

```awk '{ print $2 "\t" $3 }' example.bed```

Awk también puede usar operaciones lógicas que pueden consultar [Aquí](https://en.wikibooks.org/wiki/An_Awk_Primer/Operations). Queremos separar solo aquellas filas cuyos valores sean superiores a 15. Lo podemos hacer de la siguiente forma

```awk '$3 - $2 > 15' example.bed```

También podemos usar distitnos operadores cómo Y (&&) O (||) y NO (!). Por ejemplo seleccionemos el cromosoma 1, y cuyas posiciones sean mayores a 10

```awk '$1 ~ /chr1/ && $3 - $2 > 10' example.bed``` ¿Qué se quería decir aquí?

Ahora hagamos lo mismo, pero capturando chromosomas diferentes a chromosoma 1. ¿Cómo lo harían?

Ahora selección los cromosomas 2 y 3. ¿Cómo lo harían?

## Ejercicio 7

Aprenderémos a usar dos herramientas súper importantes de ```awk```, se llama ```BEGIN``` y ```END```.

 ```BEGIN``` especifica que hacer antes de que la primera línea sea leido y  ```END``` especifíca que hacer después de que todas la líneas sean interpretadas. Por ejemplo calculemos el valor e la longitud de las cosas.

 ```awk 'BEGIN{ s = 0 }; { s += ($3-$2) }; END{ print "mean: " s/NR };' example.bed```

Fijémonos Ahora en el ```NR```, es un símbolo que representa el número de lineas, por eso lo usamos como división.

Sabiendo NR significa fila, extraigan las filas de la 2 a la 4 del archivo example.bed

## Ejercicio 8

Ahora aprenderémos a usar ```sed``` que significa *Stream EDitor*. Basicamnete hacemos cosas similares a la de un editor de texto, pero sin necesidad de abrir un archivo. Cómo en ```awk``` hay que intentar hacer comandos simples.

Revisemos de nuevo nuestro archivo *.bed. Observemos cómo se ve.

Ahora remplazarémos la palabra chr por chromosoma, es súper fácil.
```sed 's/chr/cromosoma/' example.bed | head -n 3``` ¿Sirvió?. Esto funciona súper bien para un archivo pequeño como el que tenemos como para otro de 30 Gb. Acá la ```s``` simboliza substituir y muchas veces necesitamos que esto suceda en todo el archivo, para eso utilizaremos el flag ```g``` que significa global ```sed 's/pattern/replace/g'```; o si necesitamos que sea sensible a mayúscula y minúscula podemos usar ```i```, ```sed 's/pattern/replace/i'```

Ahora descarguen el siguiente [ZIP](https://drive.google.com/open?id=1UejAQUdj8bRBfbGd_cAVGApuvYsYaAMx), descomprímalo y concatene todos los archivos en un solo archivo llamada puntos.txt.

Revisen cómo se ve el archivo. Necesitamos Ahora quitar la primera columna, junto con los encabezados. ¿Cómo quitamos la columna? Ahora direccionemos esto a un comando sed. ¿Cómo lo harían?

Si vieron remplazamos el encabezado por una línea vacia, muchas veces lo que necesitamos no es substituir sino eliminar para eso usarémos ```d``` *delete*, de la siguiente forma ```sed '/pattern/d'```. Úsenlo.

Una cosa fantástica de ```sed``` es que podemos usar expresiones regulares!!!!!!

miremos qué pasa aquí: ```echo "chr1:28427874-28425431" | sed -E 's/^(chr[^:]+):([0-9]+)-([0-9]+)/\1 \2 \3/'```

¿Habrá otra forma de escribirlo?

Ahora usando el Archivo de GBIF de arriba quiero que corten la columna número 13, y usando expresiones regulares dejen la primera letra del género con un punto. seguido de un espacio y el epíteto específico y que eliminene el nombre de quien describió la especie. ¿Cómo lo harían?

## Ejercicio 9

Para terminar verémos como hacer loops y funciones en bash.

En Bash podemos crear variables, igual que en R y en python por ejemplo.

```variable=85``` **¡Al crear una variable los espacios quedan prohibidos!**

Ahora vamos a imprimirla ```echo variable``` ¿Qué pasó? Aprendimos la primera lección, asi no se llaman las variables en bash. Se llaman usando el símbolo ```$``` de la siguiente manera ```echo $variable```

Podemos llamar la avariable en el contexto que queramos por ejemplo ```echo "Mi abuela ayer cumplió $variable1"``` Igual que cualquier lenguaje.

Sabiendo que son las variables, vamos a ver sólo un tipo de loop que es ```for``` loop. Si quieren revisar los otros tipos de loops pueden hacer [aquí](https://www.tldp.org/LDP/abs/html/loops.html)

creemos múltiples archivos pares de 2 a 10

 ```
count=$(seq -s " " 2 2 10)

for i in $count; do
  echo $i > "file_$i.txt";
done
```

## ![Bono](https://www.google.com/search?q=bono+u2+singing&tbm=isch&ved=2ahUKEwiEro3Vo-DnAhWIBFkKHekRBtkQ2-cCegQIABAA&oq=bono+u2+singing&gs_l=img.3..0i19.7162.8143..8344...0.0..0.153.1141.0j8......0....1..gws-wiz-img.......0i67j0j0i30j0i8i30j0i8i30i19.wIdyFoXG2j8&ei=Vo9OXoSrBYiJ5ALpo5jIDQ&bih=928&biw=1920&client=ubuntu&hs=OF#imgrc=qW2sja76rt8ExM)
Ahora vamos a divertirnos en lo que queda de clase, en parejas descarguen el siguiente archivo [VCF](https://raw.githubusercontent.com/fcsalgado/bioinformatics_urosario/master/files/dummy.vcf) y el siguiente [archivo de texto](https://raw.githubusercontent.com/fcsalgado/bioinformatics_urosario/master/files/new_key.txt). El ejercicio consiste en lo siguiente, el VCF tiene unos nombres bastante incomodos, que son barcodes producto de la secuenciación y hacen referencia a los nombres de individuos, tal cúal lo dice el archivo de texto. Lo que quiero es que remplacen esos nombres del VCF por la muestra correspondiente. ¿Cómo lo harían? Le doy una pista ```sed -i``` me permite hacer remplazos en el mismo archivo de búsqueda. Tienen hasta el próximo lunes 24 de febrero a las 11:59 PM para enviarme el código a mi correo, aquellas personas que lo logren tendrán un 0.5 extra en el parcial.
